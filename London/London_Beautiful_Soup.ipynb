{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e15e3cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36a84eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(year, gender, pg_no):\n",
    "    \n",
    "    url = (\"https://results.london-marathon.co.uk/\" + year + \n",
    "           \"/?event=MAS&num_results=1000&page=\" + str(pg_no) + \n",
    "           \"&pid=list&pidp=start&search%5Bsex%5D=\" + gender)\n",
    "    if pg_no == \"1\":\n",
    "        print()\n",
    "        print(url)\n",
    "\n",
    "    request_site = Request(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    webpage = urlopen(request_site).read()\n",
    "\n",
    "    soup = BeautifulSoup(webpage, 'lxml')\n",
    "    \n",
    "    return soup\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "341fdcd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "https://results.london-marathon.co.uk/2021/?event=MAS&num_results=1000&page=1&pid=list&pidp=start&search%5Bsex%5D=M\n",
      "\n",
      "https://results.london-marathon.co.uk/2021/?event=MAS&num_results=1000&page=1&pid=list&pidp=start&search%5Bsex%5D=M\n",
      "Reading page 1 of 22 in M\n",
      "Reading page 2 of 22 in M\n",
      "Reading page 3 of 22 in M\n",
      "Reading page 4 of 22 in M\n",
      "Reading page 5 of 22 in M\n",
      "Reading page 6 of 22 in M\n",
      "Reading page 7 of 22 in M\n",
      "Reading page 8 of 22 in M\n",
      "Reading page 9 of 22 in M\n",
      "Reading page 10 of 22 in M\n",
      "Reading page 11 of 22 in M\n",
      "Reading page 12 of 22 in M\n",
      "Reading page 13 of 22 in M\n",
      "Reading page 14 of 22 in M\n",
      "Reading page 15 of 22 in M\n",
      "Reading page 16 of 22 in M\n",
      "Reading page 17 of 22 in M\n",
      "Reading page 18 of 22 in M\n",
      "Reading page 19 of 22 in M\n",
      "Reading page 20 of 22 in M\n",
      "Reading page 21 of 22 in M\n",
      "Reading page 22 of 22 in M\n",
      "\n",
      "https://results.london-marathon.co.uk/2021/?event=MAS&num_results=1000&page=1&pid=list&pidp=start&search%5Bsex%5D=W\n",
      "\n",
      "https://results.london-marathon.co.uk/2021/?event=MAS&num_results=1000&page=1&pid=list&pidp=start&search%5Bsex%5D=W\n",
      "Reading page 1 of 15 in W\n",
      "Reading page 2 of 15 in W\n",
      "Reading page 3 of 15 in W\n",
      "Reading page 4 of 15 in W\n",
      "Reading page 5 of 15 in W\n",
      "Reading page 6 of 15 in W\n",
      "Reading page 7 of 15 in W\n",
      "Reading page 8 of 15 in W\n",
      "Reading page 9 of 15 in W\n",
      "Reading page 10 of 15 in W\n",
      "Reading page 11 of 15 in W\n",
      "Reading page 12 of 15 in W\n",
      "Reading page 13 of 15 in W\n",
      "Reading page 14 of 15 in W\n",
      "Reading page 15 of 15 in W\n"
     ]
    }
   ],
   "source": [
    "# 2021 Mass Results\n",
    "\n",
    "year = \"2021\"\n",
    "\n",
    "# choose not to authenticate security certificate\n",
    "# https://clay-atlas.com/us/blog/2021/09/26/python-en-urllib-error-ssl-certificate/\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Overall Place\", \"Gender Place\", \"Category Place\", \"Name\", \"Club\", \"Runner Number\",\n",
    "                           \"Gender\", \"Category\", \"Event\", \"Half Time\", \"Finish Time\"])\n",
    "errors = pd.DataFrame(columns=[\"Page\", \"li item\", \"Error\"])\n",
    "\n",
    "for gender in [\"M\", \"W\"]:\n",
    "\n",
    "    soup = get_soup(year, gender, \"1\")\n",
    "\n",
    "    # list_length = soup.find(\"li\", class_=\"list-group-item\").text.split(\" \")[0]\n",
    "    list_length = int(soup.find(\"li\", class_=\"list-group-item\").text.split(\" \")[0])\n",
    "    n_pages = math.trunc(list_length/1000 + 1)\n",
    "\n",
    "    for n in [*range(1,n_pages + 1)]:\n",
    "        \n",
    "        soup = get_soup(year, gender, str(n))\n",
    "        datas = soup.find_all(\"li\")\n",
    "        print(f'Reading page {n} of {n_pages} in {gender}')\n",
    "\n",
    "        for i, data in enumerate(datas):\n",
    "    #         print(data.prettify())\n",
    "            try:\n",
    "                place_overall = data.find_all('div', class_=\"list-field type-place place-secondary hidden-xs numeric\")[0].text\n",
    "                place_gender = data.find('div', class_=\"list-field type-place place-primary numeric\").text\n",
    "                place_category = data.find_all('div', class_=\"list-field type-place place-secondary hidden-xs numeric\")[1].text\n",
    "                name = data.find('h4', class_=\"list-field type-fullname\").text\n",
    "                club = data.find('div', class_=\"list-field type-field hidden-xs\").text[4:]\n",
    "                runner_no = data.find('div', class_=\"list-field type-field\").text[13:]\n",
    "                category = data.find('div', class_='list-field type-age_class').text[8:]\n",
    "                event = data.find('div', class_=\"list-field type-event_name\").text[5:]\n",
    "                half_time = data.find('div', class_=\"split list-field type-time hidden-xs\").text[5:]\n",
    "                finish_time = data.find('div', class_=\"split list-field type-time\").text[6:]\n",
    "                df.loc[len(df.index)] = [place_overall, place_gender, place_category, name, club,\n",
    "                                         runner_no, gender, category, event, half_time, finish_time]\n",
    "            except Exception as e:\n",
    "                errors.loc[len(errors.index)] = [n, i, e]\n",
    "                continue\n",
    "                \n",
    "df[[\"Overall Place\", \"Gender Place\", \"Category Place\"]] = df[[\"Overall Place\", \"Gender Place\",\n",
    "                                                              \"Category Place\"]].astype(int)\n",
    "df = df.sort_values(\"Overall Place\")\n",
    "df.to_csv(\"London_2021_mass_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48ab1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking 2021 Mass Results\n",
    "\n",
    "df = pd.read_csv(\"London_2021_mass_results.csv\")\n",
    "\n",
    "overall_places = list(df[\"Overall Place\"])\n",
    "\n",
    "missing_places = []\n",
    "\n",
    "for i in [*range(len(df.index))][1:]:\n",
    "    if i not in overall_places:\n",
    "        previous_place = i - 1\n",
    "        preprevious_place = i - 2\n",
    "        count1 = overall_places.count(previous_place)\n",
    "        count2 = overall_places.count(preprevious_place)\n",
    "        if count1 < 2 and count2 < 3:\n",
    "            print(f'{i} missing')\n",
    "            print(f'{count1} finishers in {previous_place}')\n",
    "            print(f'{count2} finishers in {preprevious_place}')\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c066f1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 35798\n",
    "\n",
    "df[(df[\"Overall Place\"] > i - 5) & \n",
    "   (df[\"Overall Place\"] < i + 6)].sort_values(\"Overall Place\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d60a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2021 Elite Results\n",
    "\n",
    "year = \"2021\"\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Overall Place\", \"Gender Place\", \"Category Place\", \"Name\", \"Club\", \"Runner Number\",\n",
    "                           \"Gender\", \"Category\", \"Event\", \"Half Time\", \"Finish Time\"])\n",
    "errors = pd.DataFrame(columns=[\"li item\", \"Error\"])\n",
    "\n",
    "for gender in [\"M\", \"W\"]:\n",
    "\n",
    "    url = (\"https://results.london-marathon.co.uk/\" + year +\n",
    "           \"/?event=ELIT&pid=list&pidp=start&search%5Bsex%5D=\" + gender)\n",
    "    html = urlopen(url)\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    datas = soup.find_all(\"li\")\n",
    "\n",
    "    print()\n",
    "    print(f'Reading {gender} in elites')\n",
    "\n",
    "    for i, data in enumerate(datas):\n",
    "#         print(data.prettify())\n",
    "        try:\n",
    "            place_overall = data.find_all('div', class_=\"list-field type-place place-secondary hidden-xs numeric\")[0].text\n",
    "            place_gender = data.find('div', class_=\"list-field type-place place-primary numeric\").text\n",
    "            place_category = data.find_all('div', class_=\"list-field type-place place-secondary hidden-xs numeric\")[1].text\n",
    "            name = data.find('h4', class_=\"list-field type-fullname\").text\n",
    "            club = data.find('div', class_=\"list-field type-field hidden-xs\").text[4:]\n",
    "            runner_no = data.find('div', class_=\"list-field type-field\").text[13:]\n",
    "            category = data.find('div', class_='list-field type-age_class').text[8:]\n",
    "            event = data.find('div', class_=\"list-field type-event_name\").text[5:]\n",
    "            half_time = data.find('div', class_=\"split list-field type-time hidden-xs\").text[5:]\n",
    "            finish_time = data.find('div', class_=\"split list-field type-time\").text[6:]\n",
    "            df.loc[len(df.index)] = [place_overall, place_gender, place_category, name, club,\n",
    "                                     runner_no, gender, category, event, half_time, finish_time]\n",
    "        except Exception as e:\n",
    "            errors.loc[len(errors.index)] = [i, e]\n",
    "            continue\n",
    "\n",
    "df[[\"Overall Place\", \"Gender Place\", \"Category Place\"]] = df[[\"Overall Place\", \"Gender Place\",\n",
    "                                                              \"Category Place\"]].astype(int)\n",
    "df = df.sort_values(\"Overall Place\")\n",
    "df.to_csv(\"London_2021_elite_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4e126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020 Elite Results\n",
    "\n",
    "year = \"2020\"\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Overall Place\", \"Gender Place\", \"Category Place\", \"Name\", \"Club\", \"Runner Number\",\n",
    "                           \"Gender\", \"Category\", \"Event\", \"Half Time\", \"Finish Time\"])\n",
    "errors = pd.DataFrame(columns=[\"li item\", \"Error\"])\n",
    "\n",
    "for gender in [\"M\", \"W\"]:\n",
    "    \n",
    "    url = (\"https://results.london-marathon.co.uk/\" + year + \n",
    "           \"/?event=LMR\" + gender + \n",
    "           \"&pid=list&pidp=results_nav&search%5Bsex%5D=\" + gender)\n",
    "    \n",
    "    html = urlopen(url)\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    datas = soup.find_all(\"li\")\n",
    "\n",
    "    print()\n",
    "    print(f'Reading {gender} in elites')\n",
    "\n",
    "    for i, data in enumerate(datas):\n",
    "#         print(data.prettify())\n",
    "        try:\n",
    "            place_overall = data.find_all('div', class_=\"list-field type-place place-secondary hidden-xs numeric\")[0].text\n",
    "            place_gender = data.find('div', class_=\"list-field type-place place-primary numeric\").text\n",
    "            place_category = data.find_all('div', class_=\"list-field type-place place-secondary hidden-xs numeric\")[1].text\n",
    "            name = data.find('h4', class_=\"list-field type-eval\").text\n",
    "            club = data.find('div', class_=\"list-field type-field hidden-xs\").text[4:]\n",
    "            runner_no = data.find('div', class_=\"list-field type-field\").text[14:]\n",
    "            category = data.find('div', class_='list-field type-age_class').text[8:]\n",
    "            event = \"Elite \" + gender\n",
    "            half_time = \"\"\n",
    "            finish_time = data.find('div', class_=\"list-field type-time\").text[6:]\n",
    "            df.loc[len(df.index)] = [place_overall, place_gender, place_category, name, club,\n",
    "                                     runner_no, gender, category, event, half_time, finish_time]\n",
    "        except IndexError:\n",
    "            continue\n",
    "#         except Exception as e:\n",
    "#             errors.loc[len(errors.index)] = [i, e]\n",
    "#             continue\n",
    "            \n",
    "df.to_csv(\"London_2020_elite_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0b600fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "https://results.london-marathon.co.uk/2019/?event=MAS&num_results=1000&page=1&pid=list&pidp=start&search%5Bsex%5D=M\n",
      "Reading page 1 of 25 in M\n",
      "Reading page 2 of 25 in M\n",
      "Reading page 3 of 25 in M\n",
      "Reading page 4 of 25 in M\n",
      "Reading page 5 of 25 in M\n",
      "Reading page 6 of 25 in M\n",
      "Reading page 7 of 25 in M\n",
      "Reading page 8 of 25 in M\n",
      "Reading page 9 of 25 in M\n",
      "Reading page 10 of 25 in M\n",
      "Reading page 11 of 25 in M\n",
      "Reading page 12 of 25 in M\n",
      "Reading page 13 of 25 in M\n",
      "Reading page 14 of 25 in M\n",
      "Reading page 15 of 25 in M\n",
      "Reading page 16 of 25 in M\n",
      "Reading page 17 of 25 in M\n",
      "Reading page 18 of 25 in M\n",
      "Reading page 19 of 25 in M\n",
      "Reading page 20 of 25 in M\n",
      "Reading page 21 of 25 in M\n",
      "Reading page 22 of 25 in M\n",
      "Reading page 23 of 25 in M\n",
      "Reading page 24 of 25 in M\n",
      "Reading page 25 of 25 in M\n",
      "\n",
      "https://results.london-marathon.co.uk/2019/?event=MAS&num_results=1000&page=1&pid=list&pidp=start&search%5Bsex%5D=W\n",
      "Reading page 1 of 18 in W\n",
      "Reading page 2 of 18 in W\n",
      "Reading page 3 of 18 in W\n",
      "Reading page 4 of 18 in W\n",
      "Reading page 5 of 18 in W\n",
      "Reading page 6 of 18 in W\n",
      "Reading page 7 of 18 in W\n",
      "Reading page 8 of 18 in W\n",
      "Reading page 9 of 18 in W\n",
      "Reading page 10 of 18 in W\n",
      "Reading page 11 of 18 in W\n",
      "Reading page 12 of 18 in W\n",
      "Reading page 13 of 18 in W\n",
      "Reading page 14 of 18 in W\n",
      "Reading page 15 of 18 in W\n",
      "Reading page 16 of 18 in W\n",
      "Reading page 17 of 18 in W\n",
      "Reading page 18 of 18 in W\n"
     ]
    }
   ],
   "source": [
    "# 2019 Mass Results\n",
    "\n",
    "year = \"2019\"\n",
    "\n",
    "# choose not to authenticate security certificate\n",
    "# https://clay-atlas.com/us/blog/2021/09/26/python-en-urllib-error-ssl-certificate/\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Overall Place\", \"Gender Place\", \"Category Place\", \"Name\", \"Club\", \"Runner Number\",\n",
    "                           \"Gender\", \"Category\", \"Event\", \"Half Time\", \"Finish Time\"])\n",
    "errors = pd.DataFrame(columns=[\"Page\", \"li item\", \"Error\"])\n",
    "\n",
    "for gender in [\"M\", \"W\"]:\n",
    "\n",
    "    soup = get_soup(year, gender, \"1\")\n",
    "\n",
    "\n",
    "    # list_length = soup.find(\"li\", class_=\"list-group-item\").text.split(\" \")[0]\n",
    "    list_length = int(soup.find(\"li\", class_=\"list-group-item\").text.split(\" \")[0])\n",
    "    n_pages = math.trunc(list_length/1000 + 1)\n",
    "\n",
    "    for n in [*range(1,n_pages + 1)]:\n",
    "\n",
    "        soup = get_soup(year, gender, n)\n",
    "        datas = soup.find_all(\"li\")\n",
    "        print(f'Reading page {n} of {n_pages} in {gender}')\n",
    "\n",
    "        for i, data in enumerate(datas):\n",
    "    #         print(data.prettify())\n",
    "            try:\n",
    "                place_overall = data.find_all('div', class_=\"list-field type-place place-secondary hidden-xs numeric\")[0].text\n",
    "                place_gender = data.find('div', class_=\"list-field type-place place-primary numeric\").text\n",
    "                place_category = data.find_all('div', class_=\"list-field type-place place-secondary hidden-xs numeric\")[1].text\n",
    "                name = data.find('h4', class_=\"list-field type-fullname\").text\n",
    "                club = data.find('div', class_=\"list-field type-field hidden-xs\").text[4:]\n",
    "                runner_no = data.find('div', class_=\"list-field type-field\").text[13:]\n",
    "                category = data.find('div', class_='list-field type-age_class').text[8:]\n",
    "                event = \"Mass\"\n",
    "                half_time = data.find('div', class_=\"split list-field type-time hidden-xs\").text[5:]\n",
    "                finish_time = data.find('div', class_=\"split list-field type-time\").text[6:]\n",
    "                df.loc[len(df.index)] = [place_overall, place_gender, place_category, name, club,\n",
    "                                         runner_no, gender, category, event, half_time, finish_time]\n",
    "            except IndexError:\n",
    "                continue\n",
    "    #         except Exception as e:\n",
    "    #             errors.loc[len(errors.index)] = [i, e]\n",
    "    #             continue\n",
    "\n",
    "df[[\"Overall Place\", \"Gender Place\", \"Category Place\"]] = df[[\"Overall Place\", \"Gender Place\",\n",
    "                                                              \"Category Place\"]].astype(int)                                                    \n",
    "df = df.sort_values(\"Overall Place\")\n",
    "df.to_csv(\"London_\" + year + \"_mass_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a40e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = \"2019\"\n",
    "gender = \"M\"\n",
    "url = (\"https://results.london-marathon.co.uk/\" + year + \n",
    "       \"/?event=MAS&num_results=1000&page=1&pid=list&pidp=start&search%5Bsex%5D=\" + gender)\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcec538",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"London_2019_mass_results.csv\")\n",
    "df[df[\"Gender\"] == \"M\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a860f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019 Elite Results\n",
    "\n",
    "year = \"2019\"\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Overall Place\", \"Gender Place\", \"Category Place\", \"Name\", \"Club\", \"Runner Number\",\n",
    "                           \"Gender\", \"Category\", \"Event\", \"Half Time\", \"Finish Time\"])\n",
    "errors = pd.DataFrame(columns=[\"li item\", \"Error\"])\n",
    "\n",
    "for gender in [\"M\", \"W\"]:\n",
    "    \n",
    "    print()\n",
    "    url = (\"https://results.london-marathon.co.uk/\" + year + \n",
    "           \"/?event=ELIT&num_results=100&pid=list&pidp=start&search%5Bsex%5D=\" + gender)    \n",
    "    print(url)\n",
    "    \n",
    "    html = urlopen(url)\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    datas = soup.find_all(\"li\")\n",
    "\n",
    "    print(f'Reading {gender} in elites')\n",
    "\n",
    "    for i, data in enumerate(datas):\n",
    "#         print(data.prettify())\n",
    "        try:\n",
    "            place_overall = data.find_all('div', class_=\"list-field type-place place-secondary hidden-xs numeric\")[0].text\n",
    "            place_gender = data.find('div', class_=\"list-field type-place place-primary numeric\").text\n",
    "            place_category = data.find_all('div', class_=\"list-field type-place place-secondary hidden-xs numeric\")[1].text\n",
    "            name = data.find('h4', class_=\"list-field type-fullname\").text\n",
    "            club = data.find('div', class_=\"list-field type-field hidden-xs\").text[4:]\n",
    "            runner_no = data.find('div', class_=\"list-field type-field\").text[14:]\n",
    "            category = data.find('div', class_='list-field type-age_class').text[8:]\n",
    "            event = \"Elite \" + gender\n",
    "            half_time = data.find('div', class_=\"split list-field type-time hidden-xs\").text[4:]\n",
    "            finish_time = data.find('div', class_=\"split list-field type-time\").text[6:]\n",
    "            df.loc[len(df.index)] = [place_overall, place_gender, place_category, name, club,\n",
    "                                     runner_no, gender, category, event, half_time, finish_time]\n",
    "        except IndexError:\n",
    "            continue\n",
    "#         except Exception as e:\n",
    "#             errors.loc[len(errors.index)] = [i, e]\n",
    "#             continue\n",
    "            \n",
    "df.to_csv(\"London_\" + year + \"_elite_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa6c031f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "https://results.london-marathon.co.uk/2018/?event=MAS&num_results=1000&page=1&pid=list&pidp=start&search%5Bsex%5D=M\n",
      "Reading page 1 of 24 in M\n",
      "Reading page 2 of 24 in M\n",
      "Reading page 3 of 24 in M\n",
      "Reading page 4 of 24 in M\n",
      "Reading page 5 of 24 in M\n",
      "Reading page 6 of 24 in M\n",
      "Reading page 7 of 24 in M\n",
      "Reading page 8 of 24 in M\n",
      "Reading page 9 of 24 in M\n",
      "Reading page 10 of 24 in M\n",
      "Reading page 11 of 24 in M\n",
      "Reading page 12 of 24 in M\n",
      "Reading page 13 of 24 in M\n",
      "Reading page 14 of 24 in M\n",
      "Reading page 15 of 24 in M\n",
      "Reading page 16 of 24 in M\n",
      "Reading page 17 of 24 in M\n",
      "Reading page 18 of 24 in M\n",
      "Reading page 19 of 24 in M\n",
      "Reading page 20 of 24 in M\n",
      "Reading page 21 of 24 in M\n",
      "Reading page 22 of 24 in M\n",
      "Reading page 23 of 24 in M\n",
      "Reading page 24 of 24 in M\n",
      "\n",
      "https://results.london-marathon.co.uk/2018/?event=MAS&num_results=1000&page=1&pid=list&pidp=start&search%5Bsex%5D=W\n",
      "Reading page 1 of 17 in W\n",
      "Reading page 2 of 17 in W\n",
      "Reading page 3 of 17 in W\n",
      "Reading page 4 of 17 in W\n",
      "Reading page 5 of 17 in W\n",
      "Reading page 6 of 17 in W\n",
      "Reading page 7 of 17 in W\n",
      "Reading page 8 of 17 in W\n",
      "Reading page 9 of 17 in W\n",
      "Reading page 10 of 17 in W\n",
      "Reading page 11 of 17 in W\n",
      "Reading page 12 of 17 in W\n",
      "Reading page 13 of 17 in W\n",
      "Reading page 14 of 17 in W\n",
      "Reading page 15 of 17 in W\n",
      "Reading page 16 of 17 in W\n",
      "Reading page 17 of 17 in W\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "# 2018 Mass Results\n",
    "\n",
    "year = \"2018\"\n",
    "\n",
    "# choose not to authenticate security certificate\n",
    "# https://clay-atlas.com/us/blog/2021/09/26/python-en-urllib-error-ssl-certificate/\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Overall Place\", \"Gender Place\", \"Category Place\", \"Name\", \"Club\", \"Runner Number\",\n",
    "                           \"Gender\", \"Category\", \"Event\", \"Half Time\", \"Finish Time\"])\n",
    "errors = pd.DataFrame(columns=[\"Page\", \"tr item\", \"Error\"])\n",
    "\n",
    "for gender in [\"M\", \"W\"]:\n",
    "\n",
    "    soup = get_soup(year, gender, \"1\")\n",
    "\n",
    "\n",
    "    # list_length = soup.find(\"li\", class_=\"list-group-item\").text.split(\" \")[0]\n",
    "    list_length = int(soup.find(\"div\", class_=\"list-info-text\").text.split(\" \")[0])\n",
    "    n_pages = math.trunc(list_length/1000 + 1)\n",
    "\n",
    "    for n in [*range(1,n_pages + 1)]:\n",
    "\n",
    "        soup = get_soup(year, gender, n)\n",
    "        datas = soup.find_all(\"tr\")\n",
    "\n",
    "        print(f'Reading page {n} of {n_pages} in {gender}')\n",
    "\n",
    "        for i, data in enumerate(datas):\n",
    "#             print(data.prettify())\n",
    "            try:\n",
    "                place_overall = data.find_all('td')[0].text\n",
    "                place_gender = data.find_all('td')[1].text\n",
    "                place_category = data.find_all('td')[2].text\n",
    "                name = data.find_all('td')[3].text[1:-1]\n",
    "                club = data.find_all('td')[4].text\n",
    "                runner_no = data.find_all('td')[5].text\n",
    "                category = data.find_all('td')[6].text\n",
    "                event = \"Mass\"\n",
    "                half_time = data.find_all('td')[7].text\n",
    "                finish_time = data.find_all('td')[8].text\n",
    "                df.loc[len(df.index)] = [place_overall, place_gender, place_category, name, club,\n",
    "                                         runner_no, gender, category, event, half_time, finish_time]\n",
    "#             except IndexError:\n",
    "#                 continue\n",
    "            except Exception as e:\n",
    "                errors.loc[len(errors.index)] = [n, i, e]\n",
    "                continue\n",
    "\n",
    "df[\"Overall Place\"] = pd.to_numeric(df[\"Overall Place\"], errors='coerce')\n",
    "df[\"Gender Place\"] = pd.to_numeric(df[\"Gender Place\"], errors='coerce')\n",
    "df[\"Category Place\"] = pd.to_numeric(df[\"Category Place\"], errors='coerce')\n",
    "\n",
    "df = df.sort_values(\"Overall Place\")\n",
    "df.to_csv(\"London_\" + year + \"_mass_results.csv\", index=False)\n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fdb5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"London_2018_mass_results.csv\")\n",
    "df[df[\"Gender\"] == \"M\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00fd1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2018 Elite Results\n",
    "\n",
    "year = \"2018\"\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Overall Place\", \"Gender Place\", \"Category Place\", \"Name\", \"Club\", \"Runner Number\",\n",
    "                           \"Gender\", \"Category\", \"Event\", \"Half Time\", \"Finish Time\"])\n",
    "errors = pd.DataFrame(columns=[\"li item\", \"Error\"])\n",
    "\n",
    "for gender in [\"M\", \"W\"]:\n",
    "    \n",
    "    print()\n",
    "    url = (\"https://results.london-marathon.co.uk/\" + year + \n",
    "           \"/?event=ELIT&num_results=100&pid=list&pidp=start&search%5Bsex%5D=\" + gender)    \n",
    "    print(url)\n",
    "    \n",
    "    html = urlopen(url)\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    datas = soup.find_all(\"tr\")\n",
    "    print(len(datas))\n",
    "\n",
    "    print(f'Reading {gender} in elites')\n",
    "\n",
    "    for i, data in enumerate(datas[1:]):\n",
    "#         print(data.prettify())\n",
    "        try:\n",
    "            place_overall = data.find_all('td')[0].text\n",
    "            place_gender = data.find_all('td')[1].text\n",
    "            place_category = data.find_all('td')[2].text\n",
    "            name = data.find_all('td')[3].text[1:-1]\n",
    "            club = data.find_all('td')[4].text\n",
    "            runner_no = data.find_all('td')[5].text\n",
    "            category = data.find_all('td')[6].text\n",
    "            event = \"Elite\"\n",
    "            half_time = data.find_all('td')[7].text\n",
    "            finish_time = data.find_all('td')[8].text\n",
    "            df.loc[len(df.index)] = [place_overall, place_gender, place_category, name, club,\n",
    "                                     runner_no, gender, category, event, half_time, finish_time]\n",
    "        except IndexError:\n",
    "            continue\n",
    "#         except Exception as e:\n",
    "# #             errors.loc[len(errors.index)] = [i, e]\n",
    "#             print(i, e)\n",
    "#             continue\n",
    "df[[\"Overall Place\", \"Gender Place\", \"Category Place\"]] = df[[\"Overall Place\", \"Gender Place\",\n",
    "                                                              \"Category Place\"]].astype(int)                                                    \n",
    "df = df.sort_values(\"Overall Place\")            \n",
    "df.to_csv(\"London_\" + year + \"_elite_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96ee46a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "https://results.london-marathon.co.uk/2017/?event=MAS&num_results=1000&page=1&pid=list&pidp=start&search%5Bsex%5D=M\n",
      "Reading page 1 of 24 in M\n",
      "Reading page 2 of 24 in M\n",
      "Reading page 3 of 24 in M\n",
      "Reading page 4 of 24 in M\n",
      "Reading page 5 of 24 in M\n",
      "Reading page 6 of 24 in M\n",
      "Reading page 7 of 24 in M\n",
      "Reading page 8 of 24 in M\n",
      "Reading page 9 of 24 in M\n",
      "Reading page 10 of 24 in M\n",
      "Reading page 11 of 24 in M\n",
      "Reading page 12 of 24 in M\n",
      "Reading page 13 of 24 in M\n",
      "Reading page 14 of 24 in M\n",
      "Reading page 15 of 24 in M\n",
      "Reading page 16 of 24 in M\n",
      "Reading page 17 of 24 in M\n",
      "Reading page 18 of 24 in M\n",
      "Reading page 19 of 24 in M\n",
      "Reading page 20 of 24 in M\n",
      "Reading page 21 of 24 in M\n",
      "Reading page 22 of 24 in M\n",
      "Reading page 23 of 24 in M\n",
      "Reading page 24 of 24 in M\n",
      "\n",
      "https://results.london-marathon.co.uk/2017/?event=MAS&num_results=1000&page=1&pid=list&pidp=start&search%5Bsex%5D=W\n",
      "Reading page 1 of 16 in W\n",
      "Reading page 2 of 16 in W\n",
      "Reading page 3 of 16 in W\n",
      "Reading page 4 of 16 in W\n",
      "Reading page 5 of 16 in W\n",
      "Reading page 6 of 16 in W\n",
      "Reading page 7 of 16 in W\n",
      "Reading page 8 of 16 in W\n",
      "Reading page 9 of 16 in W\n",
      "Reading page 10 of 16 in W\n",
      "Reading page 11 of 16 in W\n",
      "Reading page 12 of 16 in W\n",
      "Reading page 13 of 16 in W\n",
      "Reading page 14 of 16 in W\n",
      "Reading page 15 of 16 in W\n",
      "Reading page 16 of 16 in W\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "# 2017 Mass Results\n",
    "\n",
    "year = \"2017\"\n",
    "\n",
    "# choose not to authenticate security certificate\n",
    "# https://clay-atlas.com/us/blog/2021/09/26/python-en-urllib-error-ssl-certificate/\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Overall Place\", \"Gender Place\", \"Category Place\", \"Name\", \"Club\", \"Runner Number\",\n",
    "                           \"Gender\", \"Category\", \"Event\", \"Half Time\", \"Finish Time\"])\n",
    "errors = pd.DataFrame(columns=[\"Page\", \"tr item\", \"Error\"])\n",
    "\n",
    "for gender in [\"M\", \"W\"]:\n",
    "\n",
    "    soup = get_soup(year, gender, \"1\")\n",
    "\n",
    "\n",
    "    # list_length = soup.find(\"li\", class_=\"list-group-item\").text.split(\" \")[0]\n",
    "    list_length = int(soup.find(\"div\", class_=\"list-info-text\").text.split(\" \")[0])\n",
    "    n_pages = math.trunc(list_length/1000 + 1)\n",
    "\n",
    "    for n in [*range(1,n_pages + 1)]:\n",
    "\n",
    "        soup = get_soup(year, gender, n)\n",
    "        datas = soup.find_all(\"tr\")\n",
    "\n",
    "        print(f'Reading page {n} of {n_pages} in {gender}')\n",
    "\n",
    "        for i, data in enumerate(datas):\n",
    "#             print(data.prettify())\n",
    "            try:\n",
    "                place_overall = data.find_all('td')[0].text\n",
    "                place_gender = data.find_all('td')[1].text\n",
    "                place_category = data.find_all('td')[2].text\n",
    "                name = data.find_all('td')[3].text[1:-1]\n",
    "                club = data.find_all('td')[4].text\n",
    "                runner_no = data.find_all('td')[5].text\n",
    "                category = data.find_all('td')[6].text\n",
    "                event = \"Mass\"\n",
    "                half_time = data.find_all('td')[7].text\n",
    "                finish_time = data.find_all('td')[8].text\n",
    "                df.loc[len(df.index)] = [place_overall, place_gender, place_category, name, club,\n",
    "                                         runner_no, gender, category, event, half_time, finish_time]\n",
    "#             except IndexError:\n",
    "#                 continue\n",
    "            except Exception as e:\n",
    "                errors.loc[len(errors.index)] = [n, i, e]\n",
    "                continue\n",
    "\n",
    "df[\"Overall Place\"] = pd.to_numeric(df[\"Overall Place\"], errors='coerce')\n",
    "df[\"Gender Place\"] = pd.to_numeric(df[\"Gender Place\"], errors='coerce')\n",
    "df[\"Category Place\"] = pd.to_numeric(df[\"Category Place\"], errors='coerce')\n",
    "\n",
    "df = df.sort_values(\"Overall Place\")\n",
    "df.to_csv(\"London_\" + year + \"_mass_results.csv\", index=False)\n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578cce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"London_2017_mass_results.csv\")\n",
    "# df[df[\"Name\"].str.contains(\"Kevin\")]\n",
    "# df[df[\"Runner Number\"] == 43227]\n",
    "# df[df[\"Club\"].str.contains(\"Kent\")].head(20)\n",
    "df[df[\"Gender\"] == \"M\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e73c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2017 Elite Results\n",
    "\n",
    "year = \"2017\"\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Overall Place\", \"Gender Place\", \"Category Place\", \"Name\", \"Club\", \"Runner Number\",\n",
    "                           \"Gender\", \"Category\", \"Event\", \"Half Time\", \"Finish Time\"])\n",
    "errors = pd.DataFrame(columns=[\"li item\", \"Error\"])\n",
    "\n",
    "for gender in [\"M\", \"W\"]:\n",
    "    \n",
    "    print()\n",
    "    url = (\"https://results.london-marathon.co.uk/\" + year + \n",
    "           \"/?event=ELIT&num_results=100&pid=list&pidp=start&search%5Bsex%5D=\" + gender)    \n",
    "    print(url)\n",
    "    \n",
    "    html = urlopen(url)\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    datas = soup.find_all(\"tr\")\n",
    "    print(len(datas))\n",
    "\n",
    "    print(f'Reading {gender} in elites')\n",
    "\n",
    "    for i, data in enumerate(datas[1:]):\n",
    "#         print(data.prettify())\n",
    "        try:\n",
    "            place_overall = data.find_all('td')[0].text\n",
    "            place_gender = data.find_all('td')[1].text\n",
    "            place_category = data.find_all('td')[2].text\n",
    "            name = data.find_all('td')[3].text[1:-1]\n",
    "            club = data.find_all('td')[4].text\n",
    "            runner_no = data.find_all('td')[5].text\n",
    "            category = data.find_all('td')[6].text\n",
    "            event = \"Elite\"\n",
    "            half_time = data.find_all('td')[7].text\n",
    "            finish_time = data.find_all('td')[8].text\n",
    "            df.loc[len(df.index)] = [place_overall, place_gender, place_category, name, club,\n",
    "                                     runner_no, gender, category, event, half_time, finish_time]\n",
    "        except IndexError:\n",
    "            continue\n",
    "#         except Exception as e:\n",
    "# #             errors.loc[len(errors.index)] = [i, e]\n",
    "#             print(i, e)\n",
    "#             continue\n",
    "df[[\"Overall Place\", \"Gender Place\", \"Category Place\"]] = df[[\"Overall Place\", \"Gender Place\",\n",
    "                                                              \"Category Place\"]].astype(int)                                                    \n",
    "df = df.sort_values(\"Overall Place\")            \n",
    "df.to_csv(\"London_\" + year + \"_elite_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb088bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "https://results.london-marathon.co.uk/2016/?event=MAS&num_results=1000&page=1&pid=list&pidp=start&search%5Bsex%5D=M\n",
      "Reading page 1 of 24 in M\n",
      "Reading page 2 of 24 in M\n",
      "Reading page 3 of 24 in M\n",
      "Reading page 4 of 24 in M\n",
      "Reading page 5 of 24 in M\n",
      "Reading page 6 of 24 in M\n",
      "Reading page 7 of 24 in M\n",
      "Reading page 8 of 24 in M\n",
      "Reading page 9 of 24 in M\n",
      "Reading page 10 of 24 in M\n",
      "Reading page 11 of 24 in M\n",
      "Reading page 12 of 24 in M\n",
      "Reading page 13 of 24 in M\n",
      "Reading page 14 of 24 in M\n",
      "Reading page 15 of 24 in M\n",
      "Reading page 16 of 24 in M\n",
      "Reading page 17 of 24 in M\n",
      "Reading page 18 of 24 in M\n",
      "Reading page 19 of 24 in M\n",
      "Reading page 20 of 24 in M\n",
      "Reading page 21 of 24 in M\n",
      "Reading page 22 of 24 in M\n",
      "Reading page 23 of 24 in M\n",
      "Reading page 24 of 24 in M\n",
      "\n",
      "https://results.london-marathon.co.uk/2016/?event=MAS&num_results=1000&page=1&pid=list&pidp=start&search%5Bsex%5D=W\n",
      "Reading page 1 of 16 in W\n",
      "Reading page 2 of 16 in W\n",
      "Reading page 3 of 16 in W\n",
      "Reading page 4 of 16 in W\n",
      "Reading page 5 of 16 in W\n",
      "Reading page 6 of 16 in W\n",
      "Reading page 7 of 16 in W\n",
      "Reading page 8 of 16 in W\n",
      "Reading page 9 of 16 in W\n",
      "Reading page 10 of 16 in W\n",
      "Reading page 11 of 16 in W\n",
      "Reading page 12 of 16 in W\n",
      "Reading page 13 of 16 in W\n",
      "Reading page 14 of 16 in W\n",
      "Reading page 15 of 16 in W\n",
      "Reading page 16 of 16 in W\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "# 2016 Mass Results\n",
    "\n",
    "year = \"2016\"\n",
    "\n",
    "# choose not to authenticate security certificate\n",
    "# https://clay-atlas.com/us/blog/2021/09/26/python-en-urllib-error-ssl-certificate/\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Overall Place\", \"Gender Place\", \"Category Place\", \"Name\", \"Club\", \"Runner Number\",\n",
    "                           \"Gender\", \"Category\", \"Event\", \"Half Time\", \"Finish Time\"])\n",
    "errors = pd.DataFrame(columns=[\"Page\", \"tr item\", \"Error\"])\n",
    "\n",
    "for gender in [\"M\", \"W\"]:\n",
    "\n",
    "    soup = get_soup(year, gender, \"1\")\n",
    "\n",
    "    # list_length = soup.find(\"li\", class_=\"list-group-item\").text.split(\" \")[0]\n",
    "    list_length = int(soup.find(\"div\", class_=\"list-info-text\").text.split(\" \")[0])\n",
    "    n_pages = math.trunc(list_length/1000 + 1)\n",
    "\n",
    "    for n in [*range(1,n_pages + 1)]:\n",
    "\n",
    "        soup = get_soup(year, gender, n)\n",
    "        datas = soup.find_all(\"tr\")\n",
    "\n",
    "        print(f'Reading page {n} of {n_pages} in {gender}')\n",
    "\n",
    "        for i, data in enumerate(datas):\n",
    "#             print(data.prettify())\n",
    "            try:\n",
    "                place_overall = data.find_all('td')[0].text\n",
    "                place_gender = data.find_all('td')[1].text\n",
    "                place_category = data.find_all('td')[2].text\n",
    "                name = data.find_all('td')[3].text[1:-1]\n",
    "                club = data.find_all('td')[4].text\n",
    "                runner_no = data.find_all('td')[5].text\n",
    "                category = data.find_all('td')[6].text\n",
    "                event = \"Mass\"\n",
    "                half_time = data.find_all('td')[7].text\n",
    "                finish_time = data.find_all('td')[8].text\n",
    "                df.loc[len(df.index)] = [place_overall, place_gender, place_category, name, club,\n",
    "                                         runner_no, gender, category, event, half_time, finish_time]\n",
    "#             except IndexError:\n",
    "#                 continue\n",
    "            except Exception as e:\n",
    "                errors.loc[len(errors.index)] = [n, i, e]\n",
    "                continue\n",
    "\n",
    "df[\"Overall Place\"] = pd.to_numeric(df[\"Overall Place\"], errors='coerce')\n",
    "df[\"Gender Place\"] = pd.to_numeric(df[\"Gender Place\"], errors='coerce')\n",
    "df[\"Category Place\"] = pd.to_numeric(df[\"Category Place\"], errors='coerce')\n",
    "\n",
    "df = df.sort_values(\"Overall Place\")\n",
    "df.to_csv(\"London_\" + year + \"_mass_results.csv\", index=False)\n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5282bc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"London_2016_mass_results.csv\")\n",
    "df[df[\"Gender\"] == \"M\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c82781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2016 Elite Results\n",
    "\n",
    "year = \"2016\"\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Overall Place\", \"Gender Place\", \"Category Place\", \"Name\", \"Club\", \"Runner Number\",\n",
    "                           \"Gender\", \"Category\", \"Event\", \"Half Time\", \"Finish Time\"])\n",
    "errors = pd.DataFrame(columns=[\"li item\", \"Error\"])\n",
    "\n",
    "for gender in [\"M\", \"W\"]:\n",
    "    \n",
    "    print()\n",
    "    url = (\"https://results.london-marathon.co.uk/\" + year + \n",
    "           \"/?event=ELIT&num_results=100&pid=list&pidp=start&search%5Bsex%5D=\" + gender)    \n",
    "    print(url)\n",
    "    \n",
    "    html = urlopen(url)\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    datas = soup.find_all(\"tr\")\n",
    "    print(len(datas))\n",
    "\n",
    "    print(f'Reading {gender} in elites')\n",
    "\n",
    "    for i, data in enumerate(datas[1:]):\n",
    "#         print(data.prettify())\n",
    "        try:\n",
    "            place_overall = data.find_all('td')[0].text\n",
    "            place_gender = data.find_all('td')[1].text\n",
    "            place_category = data.find_all('td')[2].text\n",
    "            name = data.find_all('td')[3].text[1:-1]\n",
    "            club = data.find_all('td')[4].text\n",
    "            runner_no = data.find_all('td')[5].text\n",
    "            category = data.find_all('td')[6].text\n",
    "            event = \"Elite\"\n",
    "            half_time = data.find_all('td')[7].text\n",
    "            finish_time = data.find_all('td')[8].text\n",
    "            df.loc[len(df.index)] = [place_overall, place_gender, place_category, name, club,\n",
    "                                     runner_no, gender, category, event, half_time, finish_time]\n",
    "        except IndexError:\n",
    "            continue\n",
    "#         except Exception as e:\n",
    "# #             errors.loc[len(errors.index)] = [i, e]\n",
    "#             print(i, e)\n",
    "#             continue\n",
    "df[[\"Overall Place\", \"Gender Place\", \"Category Place\"]] = df[[\"Overall Place\", \"Gender Place\",\n",
    "                                                              \"Category Place\"]].astype(int)                                                    \n",
    "df = df.sort_values(\"Overall Place\")            \n",
    "df.to_csv(\"London_\" + year + \"_elite_results.csv\", index=False)\n",
    "\n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8b2a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"London_2016_elite_results.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a1fd4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "https://results.london-marathon.co.uk/2015/?event=MAS&num_results=1000&page=1&pid=list&pidp=start&search%5Bsex%5D=M\n",
      "Reading page 1 of 24 in M\n",
      "Reading page 2 of 24 in M\n",
      "Reading page 3 of 24 in M\n",
      "Reading page 4 of 24 in M\n",
      "Reading page 5 of 24 in M\n",
      "Reading page 6 of 24 in M\n",
      "Reading page 7 of 24 in M\n",
      "Reading page 8 of 24 in M\n",
      "Reading page 9 of 24 in M\n",
      "Reading page 10 of 24 in M\n",
      "Reading page 11 of 24 in M\n",
      "Reading page 12 of 24 in M\n",
      "Reading page 13 of 24 in M\n",
      "Reading page 14 of 24 in M\n",
      "Reading page 15 of 24 in M\n",
      "Reading page 16 of 24 in M\n",
      "Reading page 17 of 24 in M\n",
      "Reading page 18 of 24 in M\n",
      "Reading page 19 of 24 in M\n",
      "Reading page 20 of 24 in M\n",
      "Reading page 21 of 24 in M\n",
      "Reading page 22 of 24 in M\n",
      "Reading page 23 of 24 in M\n",
      "Reading page 24 of 24 in M\n",
      "\n",
      "https://results.london-marathon.co.uk/2015/?event=MAS&num_results=1000&page=1&pid=list&pidp=start&search%5Bsex%5D=W\n",
      "Reading page 1 of 15 in W\n",
      "Reading page 2 of 15 in W\n",
      "Reading page 3 of 15 in W\n",
      "Reading page 4 of 15 in W\n",
      "Reading page 5 of 15 in W\n",
      "Reading page 6 of 15 in W\n",
      "Reading page 7 of 15 in W\n",
      "Reading page 8 of 15 in W\n",
      "Reading page 9 of 15 in W\n",
      "Reading page 10 of 15 in W\n",
      "Reading page 11 of 15 in W\n",
      "Reading page 12 of 15 in W\n",
      "Reading page 13 of 15 in W\n",
      "Reading page 14 of 15 in W\n",
      "Reading page 15 of 15 in W\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "# 2015 Mass Results\n",
    "\n",
    "year = \"2015\"\n",
    "\n",
    "# choose not to authenticate security certificate\n",
    "# https://clay-atlas.com/us/blog/2021/09/26/python-en-urllib-error-ssl-certificate/\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Overall Place\", \"Gender Place\", \"Category Place\", \"Name\", \"Club\", \"Runner Number\",\n",
    "                           \"Gender\", \"Category\", \"Event\", \"Half Time\", \"Finish Time\"])\n",
    "errors = pd.DataFrame(columns=[\"Page\", \"tr item\", \"Error\"])\n",
    "\n",
    "for gender in [\"M\", \"W\"]:\n",
    "\n",
    "    soup = get_soup(year, gender, \"1\")\n",
    "\n",
    "    # list_length = soup.find(\"li\", class_=\"list-group-item\").text.split(\" \")[0]\n",
    "    list_length = int(soup.find(\"div\", class_=\"list-info-text\").text.split(\" \")[0])\n",
    "    n_pages = math.trunc(list_length/1000 + 1)\n",
    "\n",
    "    for n in [*range(1,n_pages + 1)]:\n",
    "\n",
    "        soup = get_soup(year, gender, n)\n",
    "        datas = soup.find_all(\"tr\")\n",
    "\n",
    "        print(f'Reading page {n} of {n_pages} in {gender}')\n",
    "\n",
    "        for i, data in enumerate(datas):\n",
    "#             print(data.prettify())\n",
    "            try:\n",
    "                place_overall = data.find_all('td')[0].text\n",
    "                place_gender = data.find_all('td')[1].text\n",
    "                place_category = data.find_all('td')[2].text\n",
    "                name = data.find_all('td')[3].text[1:-1]\n",
    "                club = data.find_all('td')[4].text\n",
    "                runner_no = data.find_all('td')[5].text\n",
    "                category = data.find_all('td')[6].text\n",
    "                event = \"Mass\"\n",
    "                half_time = data.find_all('td')[7].text\n",
    "                finish_time = data.find_all('td')[8].text\n",
    "                df.loc[len(df.index)] = [place_overall, place_gender, place_category, name, club,\n",
    "                                         runner_no, gender, category, event, half_time, finish_time]\n",
    "#             except IndexError:\n",
    "#                 continue\n",
    "            except Exception as e:\n",
    "                errors.loc[len(errors.index)] = [n, i, e]\n",
    "                continue\n",
    "\n",
    "df[\"Overall Place\"] = pd.to_numeric(df[\"Overall Place\"], errors='coerce')\n",
    "df[\"Gender Place\"] = pd.to_numeric(df[\"Gender Place\"], errors='coerce')\n",
    "df[\"Category Place\"] = pd.to_numeric(df[\"Category Place\"], errors='coerce')\n",
    "\n",
    "df = df.sort_values(\"Overall Place\")\n",
    "df.to_csv(\"London_\" + year + \"_mass_results.csv\", index=False)\n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbc677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"London_2015_mass_results.csv\")\n",
    "df[df[\"Gender\"] == \"M\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9432aad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2015 Elite Results\n",
    "\n",
    "year = \"2015\"\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Overall Place\", \"Gender Place\", \"Category Place\", \"Name\", \"Club\", \"Runner Number\",\n",
    "                           \"Gender\", \"Category\", \"Event\", \"Half Time\", \"Finish Time\"])\n",
    "errors = pd.DataFrame(columns=[\"li item\", \"Error\"])\n",
    "\n",
    "for gender in [\"M\", \"W\"]:\n",
    "    \n",
    "    print()\n",
    "    url = (\"https://results.london-marathon.co.uk/\" + year + \n",
    "           \"/?event=ELIT&num_results=100&pid=list&pidp=start&search%5Bsex%5D=\" + gender)    \n",
    "    print(url)\n",
    "    \n",
    "    html = urlopen(url)\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    datas = soup.find_all(\"tr\")\n",
    "    print(len(datas))\n",
    "\n",
    "    print(f'Reading {gender} in elites')\n",
    "\n",
    "    for i, data in enumerate(datas[1:]):\n",
    "#         print(data.prettify())\n",
    "        try:\n",
    "            place_overall = data.find_all('td')[0].text\n",
    "            place_gender = data.find_all('td')[1].text\n",
    "            place_category = data.find_all('td')[2].text\n",
    "            name = data.find_all('td')[3].text[1:-1]\n",
    "            club = data.find_all('td')[4].text\n",
    "            runner_no = data.find_all('td')[5].text\n",
    "            category = data.find_all('td')[6].text\n",
    "            event = \"Elite\"\n",
    "            half_time = data.find_all('td')[7].text\n",
    "            finish_time = data.find_all('td')[8].text\n",
    "            df.loc[len(df.index)] = [place_overall, place_gender, place_category, name, club,\n",
    "                                     runner_no, gender, category, event, half_time, finish_time]\n",
    "        except IndexError:\n",
    "            continue\n",
    "#         except Exception as e:\n",
    "# #             errors.loc[len(errors.index)] = [i, e]\n",
    "#             print(i, e)\n",
    "#             continue\n",
    "# df[[\"Overall Place\", \"Gender Place\", \"Category Place\"]] = df[[\"Overall Place\", \"Gender Place\",\n",
    "#                                                               \"Category Place\"]].astype(int) \n",
    "\n",
    "df[\"Overall Place\"] = pd.to_numeric(df[\"Overall Place\"], errors='coerce')\n",
    "df[\"Gender Place\"] = pd.to_numeric(df[\"Gender Place\"], errors='coerce')\n",
    "df[\"Category Place\"] = pd.to_numeric(df[\"Category Place\"], errors='coerce')\n",
    "\n",
    "df = df.sort_values(\"Overall Place\")            \n",
    "df.to_csv(\"London_\" + year + \"_elite_results.csv\", index=False)\n",
    "\n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758f56b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"London_2015_elite_results.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7df48194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "https://results.london-marathon.co.uk/2014/?event=MAS&num_results=1000&page=1&pid=list&pidp=start&search%5Bsex%5D=M\n",
      "Reading page 1 of 23 in M\n",
      "Reading page 2 of 23 in M\n",
      "Reading page 3 of 23 in M\n",
      "Reading page 4 of 23 in M\n",
      "Reading page 5 of 23 in M\n",
      "Reading page 6 of 23 in M\n",
      "Reading page 7 of 23 in M\n",
      "Reading page 8 of 23 in M\n",
      "Reading page 9 of 23 in M\n",
      "Reading page 10 of 23 in M\n",
      "Reading page 11 of 23 in M\n",
      "Reading page 12 of 23 in M\n",
      "Reading page 13 of 23 in M\n",
      "Reading page 14 of 23 in M\n",
      "Reading page 15 of 23 in M\n",
      "Reading page 16 of 23 in M\n",
      "Reading page 17 of 23 in M\n",
      "Reading page 18 of 23 in M\n",
      "Reading page 19 of 23 in M\n",
      "Reading page 20 of 23 in M\n",
      "Reading page 21 of 23 in M\n",
      "Reading page 22 of 23 in M\n",
      "Reading page 23 of 23 in M\n",
      "\n",
      "https://results.london-marathon.co.uk/2014/?event=MAS&num_results=1000&page=1&pid=list&pidp=start&search%5Bsex%5D=W\n",
      "Reading page 1 of 14 in W\n",
      "Reading page 2 of 14 in W\n",
      "Reading page 3 of 14 in W\n",
      "Reading page 4 of 14 in W\n",
      "Reading page 5 of 14 in W\n",
      "Reading page 6 of 14 in W\n",
      "Reading page 7 of 14 in W\n",
      "Reading page 8 of 14 in W\n",
      "Reading page 9 of 14 in W\n",
      "Reading page 10 of 14 in W\n",
      "Reading page 11 of 14 in W\n",
      "Reading page 12 of 14 in W\n",
      "Reading page 13 of 14 in W\n",
      "Reading page 14 of 14 in W\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "# 2014 Mass Results\n",
    "\n",
    "year = \"2014\"\n",
    "\n",
    "# choose not to authenticate security certificate\n",
    "# https://clay-atlas.com/us/blog/2021/09/26/python-en-urllib-error-ssl-certificate/\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Overall Place\", \"Gender Place\", \"Category Place\", \"Name\", \"Club\", \"Runner Number\",\n",
    "                           \"Gender\", \"Category\", \"Event\", \"Half Time\", \"Finish Time\"])\n",
    "errors = pd.DataFrame(columns=[\"Page\", \"tr item\", \"Error\"])\n",
    "\n",
    "for gender in [\"M\", \"W\"]:\n",
    "\n",
    "    soup = get_soup(year, gender, \"1\")\n",
    "\n",
    "    # list_length = soup.find(\"li\", class_=\"list-group-item\").text.split(\" \")[0]\n",
    "    list_length = int(soup.find(\"div\", class_=\"list-info-text\").text.split(\" \")[0])\n",
    "    n_pages = math.trunc(list_length/1000 + 1)\n",
    "\n",
    "    for n in [*range(1,n_pages + 1)]:\n",
    "\n",
    "        soup = get_soup(year, gender, n)\n",
    "        datas = soup.find_all(\"tr\")\n",
    "\n",
    "        print(f'Reading page {n} of {n_pages} in {gender}')\n",
    "\n",
    "        for i, data in enumerate(datas):\n",
    "#             print(data.prettify())\n",
    "            try:\n",
    "                place_overall = data.find_all('td')[0].text\n",
    "                place_gender = data.find_all('td')[1].text\n",
    "                place_category = data.find_all('td')[2].text\n",
    "                name = data.find_all('td')[3].text[1:]\n",
    "                club = data.find_all('td')[5].text\n",
    "                runner_no = data.find_all('td')[6].text\n",
    "                category = data.find_all('td')[7].text\n",
    "                event = \"Mass\"\n",
    "                half_time = data.find_all('td')[8].text\n",
    "                finish_time = data.find_all('td')[9].text\n",
    "                df.loc[len(df.index)] = [place_overall, place_gender, place_category, name, club,\n",
    "                                         runner_no, gender, category, event, half_time, finish_time]\n",
    "#             except IndexError:\n",
    "#                 continue\n",
    "            except Exception as e:\n",
    "                errors.loc[len(errors.index)] = [n, i, e]\n",
    "                continue\n",
    "\n",
    "df[\"Overall Place\"] = pd.to_numeric(df[\"Overall Place\"], errors='coerce')\n",
    "df[\"Gender Place\"] = pd.to_numeric(df[\"Gender Place\"], errors='coerce')\n",
    "df[\"Category Place\"] = pd.to_numeric(df[\"Category Place\"], errors='coerce')\n",
    "\n",
    "df = df.sort_values(\"Overall Place\")\n",
    "df.to_csv(\"London_\" + year + \"_mass_results.csv\", index=False)\n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ae90f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"London_2014_mass_results.csv\")\n",
    "df[df[\"Gender\"] == \"M\"].head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eb5d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2014 Elite Results\n",
    "\n",
    "year = \"2014\"\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Overall Place\", \"Gender Place\", \"Category Place\", \"Name\", \"Club\", \"Runner Number\",\n",
    "                           \"Gender\", \"Category\", \"Event\", \"Half Time\", \"Finish Time\"])\n",
    "errors = pd.DataFrame(columns=[\"li item\", \"Error\"])\n",
    "\n",
    "for gender in [\"M\", \"W\"]:\n",
    "    \n",
    "    print()\n",
    "    url = (\"https://results.london-marathon.co.uk/\" + year + \n",
    "           \"/?event=ELIT&num_results=100&pid=list&pidp=start&search%5Bsex%5D=\" + gender)    \n",
    "    print(url)\n",
    "    \n",
    "    html = urlopen(url)\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    datas = soup.find_all(\"tr\")\n",
    "    print(len(datas))\n",
    "\n",
    "    print(f'Reading {gender} in elites')\n",
    "\n",
    "    for i, data in enumerate(datas[1:]):\n",
    "#         print(data.prettify())\n",
    "        try:\n",
    "            place_overall = data.find_all('td')[0].text\n",
    "            place_gender = data.find_all('td')[1].text\n",
    "            place_category = data.find_all('td')[2].text\n",
    "            name = data.find_all('td')[3].text[1:]\n",
    "            club = data.find_all('td')[5].text\n",
    "            runner_no = data.find_all('td')[6].text\n",
    "            category = data.find_all('td')[7].text\n",
    "            event = \"Mass\"\n",
    "            half_time = data.find_all('td')[8].text\n",
    "            finish_time = data.find_all('td')[9].text\n",
    "            df.loc[len(df.index)] = [place_overall, place_gender, place_category, name, club,\n",
    "                                     runner_no, gender, category, event, half_time, finish_time]\n",
    "        except IndexError:\n",
    "            continue\n",
    "#         except Exception as e:\n",
    "# #             errors.loc[len(errors.index)] = [i, e]\n",
    "#             print(i, e)\n",
    "#             continue\n",
    "df[\"Overall Place\"] = pd.to_numeric(df[\"Overall Place\"], errors='coerce')\n",
    "df[\"Gender Place\"] = pd.to_numeric(df[\"Gender Place\"], errors='coerce')\n",
    "df[\"Category Place\"] = pd.to_numeric(df[\"Category Place\"], errors='coerce')\n",
    "                                                  \n",
    "df = df.sort_values(\"Overall Place\")            \n",
    "df.to_csv(\"London_\" + year + \"_elite_results.csv\", index=False)\n",
    "\n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3a2e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"London_2014_elite_results.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b184a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "dd788441a4b657823b52da1e1dba7d818459bc322358feba149dfc6d69f1598d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
